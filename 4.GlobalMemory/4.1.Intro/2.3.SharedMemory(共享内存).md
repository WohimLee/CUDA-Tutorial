

&emsp;
# 共享内存（Shared Memory）
>声明修饰符
- 在 `核函数中` 使用如下修饰符修饰的变量存放在共享内存中
```c++
__shared__
```

共享内存是片上内存，与本地内存或全局内存相比，它具有更高的带宽和更低的延迟。它的使用类似于 CPU 一级缓存，但它是可编程的。 

>Shared Memory 与 SM、block
- 每一个 SM 都有一定数量的由线程块（block）分配的共享内存。因此，必须非常小心不要过度使用共享内存，否则将在不经意间限制活跃线程束的数量

>生命周期
- 共享内存在核函数的范围内声明，其生命周期伴随着整个线程块。当一个线程块执行 结束后，其分配的共享内存将被释放并重新分配给其他线程块

>访问共享内存
- 共享内存是线程之间相互通信的基本方式。一个块内的线程通过使用共享内存中的数据可以相互合作。访问共享内存必须同步使用如下调用：
    ```c++
    void __syncthreads();
    ```
    - 该函数设立了一个执行障碍点，即同一个线程块中的所有线程必须在其他线程被允许执行前达到该处。
    - 为线程块里所有线程设立障碍点，这样可以避免潜在的数据冲突。当一组未排序的多重访问通过不同的线程访问相同的内存地址 时，这些访问中至少有一个是可写的，这时就会出现数据冲突。_syncthreads 也会通过频繁强制 SM 到空闲状态来影响性能

>Shared Memory 与 SM
- SM 中的一级缓存和共享内存都使用 64KB 的片上内存，它通过静态划分，但在运行时可以通过如下指令进行动态配置：
    ```c++
    cudaError_t cudaFuncSetCacheConfig(
        const void* func, 
        enum cudaFuncCache cacheConfig
    )
    ```
    - 这个函数在每个核函数的基础上配置了片上内存划分，为func指定的核函数设置了cacheConfig 配置：
        - `cudaFuncCachePreferNone`: 没有参考值（默认）
        - `cudaFuncCachePreferShared`: 建议 48KB 的共享内存和 16KB 的 L1 缓存
        - `cudaFuncCachePreferL1`: 建议 48KB 的 L1 缓存和 16KB 的共享内存
        - `cudaFuncCachePreferEqual`: 相同 size 的 L1 缓存和共享内存，都是 32KB
