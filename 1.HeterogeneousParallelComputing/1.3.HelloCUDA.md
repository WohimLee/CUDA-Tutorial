&emsp;
# Hello CUDA

# 1 如何学习 CUDA
## 1.1 CPU
CPU 编程和 GPU 编程的主要区别是程序员对 GPU 架构的熟悉程度。用并行思维进行思考并对 GPU 架构有了基本的了解，会使你编写规模达到成百上千个核的并行程序，如同写串行程序一样简单。 

如果你想编写一个像并行程序一样高效的代码，那么你需要对 CPU 架构有基本的了解。例如，数据局部性在并行编程中是一个非常重要的概念。数据局部性指的是数据重用，以降低内存访问的延迟。

数据局部性有两种基本类型
- 时间局部性是指在相对较短的时间段内数据和/或资源的重用
- 空间局部性是指在相对较接近的存储空间内数据元素的重用

现代的 CPU 架构使用大容量缓存来优化具有良好空间局部性和时间局部性的应用程序。设计高效利用 CPU 缓存的算法是程序员的工作。程序员必须处理低层的缓存优化，但由于线程在底层架构中的安排是透明的，所以这一点程序员是没有办法优化的。 

&emsp;
## 1.2 CUDA
CUDA 中有内存层次和线程层次的概念，使用如下结构，有助于你对线程执行进行更高层次的控制和调度： 
- 内存层次结构 
- 线程层次结构 

例如，在CUDA编程模型中使用的共享内存（一个特殊的内存）。共享内存可以视为一个被软件管理的高速缓存，通过为主内存节省带宽来大幅度提高运行速度。

有了共享内存，你可以直接控制代码的数据局部性。 当用ANSI C语言编写一个并行程序时，你需要使用pthreads或者OpenMP来显式地组织线程，这两项技术使得在大多数处理器架构以及操作系统中支持并行编程。

当用 CUDA C 编写程序时，实际上你只编写了被单个线程调用的一小段串行代码。GPU 处理这个内核函数，然后通过启动成千上万个线程来实现并行化，所有的线程都执行相同的计算。

CUDA 编程模型提供了一个层次化地组织线程的方法，它直接影响到线程在 GPU上的执行顺序。 因为 CUDA C 是 C语言的扩展，通常可以直接将 C 程序移植到 CUDA C 程序中。概念上，剥离代码中的循环后产生 CUDA C 实现的内核代码。 

CUDA抽象了硬件细节，且不需要将应用程序映射到传统图形API上。CUDA核中有 3 个关键抽象：
- 线程组的层次结构
- 内存的层次结构
- 障碍同步

这3个抽象是最小的一组语言扩展。随着CUDA版本的更新，NVIDIA正在对并行编程进行不断简化。尽管一些人仍然认为CUDA的概念比较低级，但如果稍稍提高抽象级，对你控制应用程序和平台之间的互动关系来说会增加很大难度。如果那样的话，不管你掌握了多少底层架构的知识， 你的应用程序的性能都将超出控制。 因此，你的目标应是学习 GPU 架构的基础及掌握 CUDA 开发工具和环境。

&emsp;
## 1.3 CUDA 开发环境

NVIDIA为C和C++开发人员提供了综合的开发环境以创建GPU加速应用程序，包括以下几种
- NVIDIA Nsight 集成开发环境 
- CUDA-GDB 命令行调试器 
- 用于性能分析的可视化和命令行分析器 
- CUDA-MEMCHECK 内存分析器 
- GPU设备管理工具 

当你熟悉这些工具的使用之后，你会发现使用 CUDA C语 言进行编程是非常简单高效的。


&emsp;
# 2 第一个 CUDA 程序
>相关命令
```
which nvcc      # 查看编译器路径
nvcc -V         # 查看 nvcc 编译器版本
ls -l /dev/nv*  # 查看 NVIDIA 设备
```

>CUDA C 程序
1. 用专用扩展名`.cu`来创建一个源文件
2. 使用 `CUDA nvcc` 编译器来编译程序
3. 从命令行运行可执行文件，这个文件有可在GPU上运行的内核代码

>CUDA 编程结构5个主要步骤
1. 分配 GPU 内存
2. 从 CPU 内存中拷贝数据到 GPU 内存
3. 调用 CUDA 内核函数来完成程序指定的运算
4. 将数据从 GPU 拷回 CPU 内存
5. 释放 GPU 内存空间

>NCVV
- nvcc编译器选项（http://docs.nvidia.com/cuda/cuda-compiler- driver-nvcc/index.html）

nvcc 封装了几种内部编译工具，CUDA 编译器允许通过命令行选项在不同阶段启动不同的工具完成编译工作

-Xcompiler 用于指定命令行选项是指向 C 编译器还是预处理器

&emsp;
>Makefile
```makefile
cpp_srcs := $(shell find src -name "*.cpp")
cpp_objs := $(patsubst src/%.cpp,objs/%.o,$(cpp_srcs))
cu_srcs  := $(shell find src -name "*.cu")
cu_objs  := $(patsubst src/%.cu,objs/%.cuo,$(cu_srcs))

include_paths  := /usr/local/cuda-11/include 

library_paths  := /usr/local/cuda-11/lib64

link_libraries := cudart  cublas \
                  pthread
			

I_options := $(include_paths:%=-I%)
l_options := $(link_libraries:%=-l%)
L_options := $(library_paths:%=-L%)
r_options := $(library_paths:%=-Wl,-rpath=%)

cpp_compile_options := -m64 -w -O3 -g -std=c++11 -fpic -pthread \
					   -fopenmp
cpp_compile_options += $(I_options)

cu_compile_options  := -m64 -w -O3 -g -std=c++11 -Xcompiler -pthread -Xcompiler -fpic\
					   -Xcompiler -fopenmp 
cu_compile_options  += $(I_options)

linking_options  := $(l_options) $(L_options) $(r_options)


debug : 
	@echo $(cu_objs)

objs/%.o : src/%.cpp
	@mkdir -p $(dir $@)
	@g++ -c $^ -o $@ $(cpp_compile_options)

objs/%.cuo : src/%.cu
	@echo Compile $^
	@mkdir -p $(dir $@)
	@nvcc -c $^ -o $@ $(cu_compile_options)

workspace/exec : $(cpp_objs) $(cu_objs)
	@echo Link $@
	@mkdir -p $(dir $@)
	@g++ $^ -o $@ $(linking_options) 

run : workspace/exec
	@./$<

clean :
	@rm -rf objs workspace/exec

.PHONY : run clean debug
```

&emsp;
>hello.cu
```c++
#include <stdio.h>

__global__ void helloFromGPU (void)
{
    printf("Hello World from GPU!\n");

}

int main(void)
{
    // hello from cpu
    printf("Hello World from CPU!\n");
    helloFromGPU <<<1, 10>>>();
    cudaDeviceReset();
    return 0;
}
```


- 修饰符 \_\_global__ 告诉编译器这个函数将会从 CPU 中调用，然后在 GPU 上执行
- 三重尖括号意味着从主线程到设备端代码的调用。一个内核函数通过一组线程来执行，所有线程执行相同的代码。三重尖括号里面的参数是执行配置，用来说明使用多少线程来执行内核函数。在这个例子中，有10个GPU线程被调用
- 函数 cudaDeviceRest() 用来显式地释放和清空当前进程中与当前设备有关的所有资 源。











